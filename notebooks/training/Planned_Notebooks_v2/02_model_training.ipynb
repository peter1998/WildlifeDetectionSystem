{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5dfa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.3\n",
      "Platform: Linux-6.8.0-58-generic-x86_64-with-glibc2.39\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "GPU device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Number of GPUs: 1\n",
      "GPU Memory: 5.76 GB\n",
      "âœ… numpy is installed (version: 2.1.1)\n",
      "âœ… matplotlib is installed (version: 3.10.1)\n",
      "âœ… pandas is installed (version: 2.2.3)\n",
      "âœ… ultralytics is installed (version: 8.3.106)\n",
      "\n",
      "Project root path: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem\n",
      "Current working directory: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/notebooks/training/Planned_Notebooks_v2\n",
      "\n",
      "Environment setup check complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Environment Setup and Dependencies\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Print Python and environment information\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "\n",
    "# Check for CUDA\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available - training will use CPU\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch is not installed - you'll need to install it with pip install torch torchvision\")\n",
    "\n",
    "# Check for other required libraries\n",
    "required_packages = ['numpy', 'matplotlib', 'pandas', 'ultralytics']\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        module = __import__(package.replace('-', '_'))\n",
    "        print(f\"âœ… {package} is installed (version: {module.__version__})\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {package} is NOT installed - use pip install {package}\")\n",
    "    except AttributeError:\n",
    "        print(f\"âœ… {package} is installed (version unknown)\")\n",
    "\n",
    "# Manually set the project root path to ensure accuracy\n",
    "project_root = \"/home/peter/Desktop/TU PHD/WildlifeDetectionSystem\"\n",
    "print(f\"\\nProject root path: {project_root}\")\n",
    "\n",
    "# Output the current working directory for reference\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Create tracking directory\n",
    "tracking_dir = os.path.join(project_root, \"tracking\")\n",
    "os.makedirs(tracking_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\nEnvironment setup check complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bfe035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root path: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem\n",
      "Found configuration from notebook 1: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/config/notebook_data_20250510_0038.json\n",
      "\n",
      "Loaded configuration with timestamp: 20250510_0038\n",
      "Number of classes: 30\n",
      "Number of taxonomic groups: 5\n",
      "Standard dataset: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038\n",
      "Hierarchical dataset: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_hierarchical_test_01_20250510_0038\n",
      "âœ… Standard YOLO dataset exists\n",
      "   Classes in data.yaml: 30\n",
      "âœ… Hierarchical YOLO dataset exists\n",
      "   Groups in data.yaml: 5\n",
      "\n",
      "Output paths for trained models:\n",
      "- Standard model: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/models/trained/wildlife_detector_20250510_0114\n",
      "- Hierarchical model: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/models/trained/wildlife_detector_hierarchical_20250510_0114\n",
      "\n",
      "Training configuration saved to: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/config/training_config_20250510_0114.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Configuration from Notebook 1\n",
    "# Find and load the configuration generated by the data preparation notebook\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "# Manually set the project root path to ensure accuracy - this makes the cell self-contained\n",
    "project_root = \"/home/peter/Desktop/TU PHD/WildlifeDetectionSystem\"\n",
    "print(f\"Project root path: {project_root}\")\n",
    "\n",
    "def find_latest_config(config_dir, prefix=\"notebook_data_\"):\n",
    "    \"\"\"Find the latest configuration file based on timestamp in filename\"\"\"\n",
    "    config_files = [f for f in os.listdir(config_dir) if f.startswith(prefix) and f.endswith('.json')]\n",
    "    if not config_files:\n",
    "        return None\n",
    "    \n",
    "    # Sort by timestamp (assuming format notebook_data_YYYYMMDD_HHMM.json)\n",
    "    latest_config = sorted(config_files, reverse=True)[0]\n",
    "    return os.path.join(config_dir, latest_config)\n",
    "\n",
    "# Define paths\n",
    "config_dir = os.path.join(project_root, \"config\")\n",
    "if not os.path.exists(config_dir):\n",
    "    print(f\"âŒ Config directory not found: {config_dir}\")\n",
    "    print(\"Please run notebook 1 (data preparation) first\")\n",
    "else:\n",
    "    # Try to find the latest config file\n",
    "    latest_config = find_latest_config(config_dir)\n",
    "    \n",
    "    if latest_config and os.path.exists(latest_config):\n",
    "        print(f\"Found configuration from notebook 1: {latest_config}\")\n",
    "        \n",
    "        # Load configuration\n",
    "        with open(latest_config, 'r') as f:\n",
    "            notebook1_config = json.load(f)\n",
    "        \n",
    "        # Extract key paths and parameters\n",
    "        timestamp = notebook1_config[\"timestamp\"]\n",
    "        class_names = notebook1_config[\"class_names\"]\n",
    "        taxonomic_groups = notebook1_config[\"taxonomic_groups\"]\n",
    "        standard_export_path = notebook1_config[\"standard_export_path\"]\n",
    "        hierarchical_export_path = notebook1_config[\"hierarchical_export_path\"]\n",
    "        \n",
    "        print(f\"\\nLoaded configuration with timestamp: {timestamp}\")\n",
    "        print(f\"Number of classes: {len(class_names)}\")\n",
    "        print(f\"Number of taxonomic groups: {len(taxonomic_groups)}\")\n",
    "        print(f\"Standard dataset: {standard_export_path}\")\n",
    "        print(f\"Hierarchical dataset: {hierarchical_export_path}\")\n",
    "        \n",
    "        # Check if the datasets exist\n",
    "        if os.path.exists(standard_export_path):\n",
    "            print(f\"âœ… Standard YOLO dataset exists\")\n",
    "            \n",
    "            # Verify data.yaml\n",
    "            data_yaml_path = os.path.join(standard_export_path, 'data.yaml')\n",
    "            if os.path.exists(data_yaml_path):\n",
    "                with open(data_yaml_path, 'r') as f:\n",
    "                    data_yaml = yaml.safe_load(f)\n",
    "                print(f\"   Classes in data.yaml: {data_yaml.get('nc', 'unknown')}\")\n",
    "            else:\n",
    "                print(f\"âŒ data.yaml not found in standard dataset\")\n",
    "        else:\n",
    "            print(f\"âŒ Standard YOLO dataset not found: {standard_export_path}\")\n",
    "        \n",
    "        if os.path.exists(hierarchical_export_path):\n",
    "            print(f\"âœ… Hierarchical YOLO dataset exists\")\n",
    "            \n",
    "            # Verify data.yaml\n",
    "            hierarchical_yaml_path = os.path.join(hierarchical_export_path, 'data.yaml')\n",
    "            if os.path.exists(hierarchical_yaml_path):\n",
    "                with open(hierarchical_yaml_path, 'r') as f:\n",
    "                    hierarchical_yaml = yaml.safe_load(f)\n",
    "                print(f\"   Groups in data.yaml: {hierarchical_yaml.get('nc', 'unknown')}\")\n",
    "            else:\n",
    "                print(f\"âŒ data.yaml not found in hierarchical dataset\")\n",
    "        else:\n",
    "            print(f\"âŒ Hierarchical YOLO dataset not found: {hierarchical_export_path}\")\n",
    "    else:\n",
    "        print(f\"âŒ Configuration from notebook 1 not found in {config_dir}\")\n",
    "        print(\"Please run notebook 1 (data preparation) first\")\n",
    "\n",
    "# Define the output paths for this notebook\n",
    "model_save_dir = os.path.join(project_root, \"models\", \"trained\")\n",
    "reports_dir = os.path.join(project_root, \"reports\")\n",
    "timestamp_now = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Generate paths for model outputs\n",
    "standard_model_name = f\"wildlife_detector_{timestamp_now}\"\n",
    "hierarchical_model_name = f\"wildlife_detector_hierarchical_{timestamp_now}\"\n",
    "\n",
    "standard_model_path = os.path.join(model_save_dir, standard_model_name)\n",
    "hierarchical_model_path = os.path.join(model_save_dir, hierarchical_model_name)\n",
    "\n",
    "print(f\"\\nOutput paths for trained models:\")\n",
    "print(f\"- Standard model: {standard_model_path}\")\n",
    "print(f\"- Hierarchical model: {hierarchical_model_path}\")\n",
    "\n",
    "# Save the training configuration for reference and tracking\n",
    "training_config = {\n",
    "    \"notebook\": \"02_model_training\",\n",
    "    \"timestamp\": timestamp_now,\n",
    "    \"input\": {\n",
    "        \"config\": latest_config,\n",
    "        \"standard_dataset\": standard_export_path,\n",
    "        \"hierarchical_dataset\": hierarchical_export_path,\n",
    "        \"class_names\": class_names,\n",
    "        \"taxonomic_groups\": taxonomic_groups\n",
    "    },\n",
    "    \"output\": {\n",
    "        \"standard_model\": standard_model_path,\n",
    "        \"hierarchical_model\": hierarchical_model_path,\n",
    "        \"reports_dir\": reports_dir\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save configuration\n",
    "training_config_path = os.path.join(config_dir, f\"training_config_{timestamp_now}.json\")\n",
    "with open(training_config_path, 'w') as f:\n",
    "    json.dump(training_config, f, indent=2)\n",
    "\n",
    "print(f\"\\nTraining configuration saved to: {training_config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf7fff37-3849-4fbc-8430-36f6b436f4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting hardware capabilities...\n",
      "GPU detected with 5.76 GB memory\n",
      "\n",
      "Recommended Configuration Based on Hardware:\n",
      "- Model: YOLOv8s (Small)\n",
      "- Parameters: 11.2M\n",
      "- Device: GPU\n",
      "- Batch Size: 4\n",
      "- Image Size: 416px\n",
      "- Workers: 2\n",
      "\n",
      "Would you like to override the recommended model size? (y/n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base model path: yolov8s.pt\n",
      "Updated training configuration with hardware and model settings.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Hardware-Aware Model Selection and Optimization\n",
    "# Automatically selects the optimal model size based on available hardware\n",
    "\n",
    "import torch \n",
    "\n",
    "def detect_hardware_capabilities():\n",
    "    \"\"\"Detect hardware capabilities and recommend model size\"\"\"\n",
    "    # Check for CUDA availability\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    \n",
    "    if not cuda_available:\n",
    "        print(\"No CUDA detected. Using CPU for training.\")\n",
    "        return {\n",
    "            \"device\": \"cpu\",\n",
    "            \"recommended_model\": \"n\",  # nano model for CPU\n",
    "            \"batch_size\": 1,\n",
    "            \"image_size\": 320,\n",
    "            \"workers\": 0\n",
    "        }\n",
    "    \n",
    "    # Get GPU memory in GB\n",
    "    try:\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        print(f\"GPU detected with {gpu_memory:.2f} GB memory\")\n",
    "        \n",
    "        # Determine model size based on available GPU memory\n",
    "        if gpu_memory >= 24:\n",
    "            # High-end GPU (RTX 3090/4090, A100, etc.)\n",
    "            return {\n",
    "                \"device\": 0,\n",
    "                \"recommended_model\": \"x\",  # largest model\n",
    "                \"batch_size\": 16,\n",
    "                \"image_size\": 640,\n",
    "                \"workers\": 4\n",
    "            }\n",
    "        elif gpu_memory >= 16:\n",
    "            # Good GPU (RTX 3080, RTX A6000, etc.)\n",
    "            return {\n",
    "                \"device\": 0,\n",
    "                \"recommended_model\": \"l\",  # large model\n",
    "                \"batch_size\": 12,\n",
    "                \"image_size\": 640,\n",
    "                \"workers\": 4\n",
    "            }\n",
    "        elif gpu_memory >= 8:\n",
    "            # Mid-range GPU (RTX 3070, RTX 2080, etc.)\n",
    "            return {\n",
    "                \"device\": 0,\n",
    "                \"recommended_model\": \"m\",  # medium model\n",
    "                \"batch_size\": 8,\n",
    "                \"image_size\": 512,\n",
    "                \"workers\": 2\n",
    "            }\n",
    "        elif gpu_memory >= 4:\n",
    "            # Entry-level GPU (GTX 1660, RTX 3050, etc.)\n",
    "            return {\n",
    "                \"device\": 0,\n",
    "                \"recommended_model\": \"s\",  # small model\n",
    "                \"batch_size\": 4,\n",
    "                \"image_size\": 416,\n",
    "                \"workers\": 2\n",
    "            }\n",
    "        else:\n",
    "            # Low-end GPU or integrated (MX series, etc.)\n",
    "            return {\n",
    "                \"device\": 0,\n",
    "                \"recommended_model\": \"n\",  # nano model\n",
    "                \"batch_size\": 2,\n",
    "                \"image_size\": 320,\n",
    "                \"workers\": 1\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting GPU properties: {e}\")\n",
    "        print(\"Defaulting to safe configuration\")\n",
    "        return {\n",
    "            \"device\": 0 if cuda_available else \"cpu\",\n",
    "            \"recommended_model\": \"n\",  # nano model for safety\n",
    "            \"batch_size\": 1,\n",
    "            \"image_size\": 320,\n",
    "            \"workers\": 0\n",
    "        }\n",
    "\n",
    "# Detect hardware capabilities\n",
    "print(\"Detecting hardware capabilities...\")\n",
    "hw_config = detect_hardware_capabilities()\n",
    "\n",
    "# Map model size to readable name and parameters\n",
    "model_sizes = {\n",
    "    \"n\": {\"name\": \"YOLOv8n\", \"description\": \"Nano\", \"params\": \"3.2M\"},\n",
    "    \"s\": {\"name\": \"YOLOv8s\", \"description\": \"Small\", \"params\": \"11.2M\"},\n",
    "    \"m\": {\"name\": \"YOLOv8m\", \"description\": \"Medium\", \"params\": \"25.9M\"},\n",
    "    \"l\": {\"name\": \"YOLOv8l\", \"description\": \"Large\", \"params\": \"43.7M\"},\n",
    "    \"x\": {\"name\": \"YOLOv8x\", \"description\": \"Extra Large\", \"params\": \"68.2M\"}\n",
    "}\n",
    "\n",
    "# Display recommended configuration\n",
    "recommended_model_size = hw_config[\"recommended_model\"]\n",
    "recommended_model = model_sizes[recommended_model_size]\n",
    "\n",
    "print(\"\\nRecommended Configuration Based on Hardware:\")\n",
    "print(f\"- Model: {recommended_model['name']} ({recommended_model['description']})\")\n",
    "print(f\"- Parameters: {recommended_model['params']}\")\n",
    "print(f\"- Device: {'GPU' if hw_config['device'] == 0 else 'CPU'}\")\n",
    "print(f\"- Batch Size: {hw_config['batch_size']}\")\n",
    "print(f\"- Image Size: {hw_config['image_size']}px\")\n",
    "print(f\"- Workers: {hw_config['workers']}\")\n",
    "\n",
    "# Allow manual override\n",
    "print(\"\\nWould you like to override the recommended model size? (y/n)\")\n",
    "override = input().strip().lower()\n",
    "if override == 'y':\n",
    "    print(\"Select model size (n=nano, s=small, m=medium, l=large, x=extra-large):\")\n",
    "    model_input = input().strip().lower()\n",
    "    if model_input in model_sizes:\n",
    "        recommended_model_size = model_input\n",
    "        recommended_model = model_sizes[recommended_model_size]\n",
    "        print(f\"Using {recommended_model['name']} ({recommended_model['description']}) with {recommended_model['params']} parameters.\")\n",
    "    else:\n",
    "        print(f\"Invalid selection. Using recommended {recommended_model['name']}.\")\n",
    "\n",
    "# Define model paths\n",
    "base_model_path = f\"yolov8{recommended_model_size}.pt\"\n",
    "print(f\"\\nBase model path: {base_model_path}\")\n",
    "\n",
    "# Save hardware configuration to the training config\n",
    "training_config[\"hardware\"] = hw_config\n",
    "training_config[\"model\"] = {\n",
    "    \"size\": recommended_model_size,\n",
    "    \"name\": recommended_model[\"name\"],\n",
    "    \"description\": recommended_model[\"description\"],\n",
    "    \"parameters\": recommended_model[\"params\"],\n",
    "    \"base_model_path\": base_model_path\n",
    "}\n",
    "\n",
    "# Update training config file\n",
    "with open(training_config_path, 'w') as f:\n",
    "    json.dump(training_config, f, indent=2)\n",
    "\n",
    "print(f\"Updated training configuration with hardware and model settings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f257b44-02ad-469e-87b5-dc46e665d7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected memory optimization profile: gpu_standard\n",
      "\n",
      "Standard Model Training Configuration:\n",
      "- epochs: 100\n",
      "- patience: 25\n",
      "- optimizer: AdamW\n",
      "- lr0: 0.001\n",
      "- device: 0\n",
      "- workers: 2\n",
      "- batch: 4\n",
      "- amp: True\n",
      "\n",
      "Hierarchical Model Training Configuration:\n",
      "- epochs: 50\n",
      "- patience: 15\n",
      "- optimizer: AdamW\n",
      "- lr0: 0.001\n",
      "- device: 0\n",
      "- workers: 2\n",
      "- batch: 4\n",
      "- amp: True\n",
      "\n",
      "Hyperparameters added to training configuration.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Training Configuration Setup\n",
    "# Define training parameters for both standard and hierarchical models\n",
    "\n",
    "# Memory optimization settings\n",
    "memory_optimizations = {\n",
    "    \"cpu\": {\n",
    "        # CPU-specific optimizations\n",
    "        \"device\": \"cpu\",\n",
    "        \"workers\": 0,\n",
    "        \"batch\": 1,\n",
    "        \"cache\": \"disk\",\n",
    "        \"imgsz\": min(hw_config[\"image_size\"], 320),  # Changed from \"image_size\" to \"imgsz\"\n",
    "        \"amp\": False  # No mixed precision on CPU\n",
    "    },\n",
    "    \"gpu_low_memory\": {\n",
    "        # For GPUs with less than 4GB memory\n",
    "        \"device\": 0,\n",
    "        \"workers\": hw_config[\"workers\"],\n",
    "        \"batch\": max(1, hw_config[\"batch_size\"] // 2),  # Reduce batch size\n",
    "        \"cache\": \"disk\",\n",
    "        \"imgsz\": min(hw_config[\"image_size\"], 384),  # Changed from \"image_size\" to \"imgsz\"\n",
    "        \"amp\": True  # Mixed precision\n",
    "    },\n",
    "    \"gpu_standard\": {\n",
    "        # For standard GPUs with sufficient memory\n",
    "        \"device\": 0,\n",
    "        \"workers\": hw_config[\"workers\"],\n",
    "        \"batch\": hw_config[\"batch_size\"],\n",
    "        \"cache\": \"ram\",\n",
    "        \"imgsz\": hw_config[\"image_size\"],  # Changed from \"image_size\" to \"imgsz\"\n",
    "        \"amp\": True  # Mixed precision\n",
    "    }\n",
    "}\n",
    "\n",
    "# Select memory optimization profile based on hardware\n",
    "if hw_config[\"device\"] == \"cpu\":\n",
    "    memory_profile = \"cpu\"\n",
    "elif hw_config[\"device\"] == 0 and torch.cuda.get_device_properties(0).total_memory / (1024**3) < 4:\n",
    "    memory_profile = \"gpu_low_memory\"\n",
    "else:\n",
    "    memory_profile = \"gpu_standard\"\n",
    "\n",
    "print(f\"Selected memory optimization profile: {memory_profile}\")\n",
    "memory_config = memory_optimizations[memory_profile]\n",
    "\n",
    "# Base hyperparameters common to both standard and hierarchical training\n",
    "base_hyperparams = {\n",
    "    # Standard YOLOv8 parameters\n",
    "    'epochs': 100,                    # Maximum number of epochs\n",
    "    'patience': 25,                   # Early stopping patience\n",
    "    'optimizer': 'AdamW',             # Optimizer (AdamW better for imbalanced data)\n",
    "    'lr0': 0.001,                     # Initial learning rate\n",
    "    'lrf': 0.01,                      # Final learning rate as a fraction of lr0\n",
    "    'momentum': 0.937,                # SGD momentum/Adam beta1\n",
    "    'weight_decay': 0.0005,           # Regularization \n",
    "    'warmup_epochs': 5,               # Warmup epochs\n",
    "    'warmup_momentum': 0.8,           # Initial warmup momentum\n",
    "    'warmup_bias_lr': 0.1,            # Initial warmup learning rate for bias\n",
    "    \n",
    "    # Loss function weights\n",
    "    'box': 7.5,                       # Box loss weight\n",
    "    'cls': 3.0,                       # Class loss weight\n",
    "    'dfl': 1.5,                       # DFL loss weight\n",
    "    \n",
    "    # Data augmentation\n",
    "    'hsv_h': 0.015,                   # HSV Hue augmentation\n",
    "    'hsv_s': 0.7,                     # HSV Saturation augmentation (higher for wildlife)\n",
    "    'hsv_v': 0.4,                     # HSV Value augmentation (for varying lighting)\n",
    "    'degrees': 10.0,                  # Rotation augmentation\n",
    "    'translate': 0.2,                 # Translation augmentation\n",
    "    'scale': 0.6,                     # Scale augmentation (stronger for wildlife)\n",
    "    'fliplr': 0.5,                    # Horizontal flip probability\n",
    "    'mosaic': 1.0,                    # Mosaic augmentation\n",
    "    'mixup': 0.1,                     # Mixup augmentation\n",
    "    'copy_paste': 0.1,                # Copy-paste augmentation (for rare classes)\n",
    "    \n",
    "    # Saving and checkpointing\n",
    "    'save': True,                     # Save model\n",
    "    'save_period': 10,                # Save checkpoints every X epochs\n",
    "    \n",
    "    # Nominal batch size for gradient accumulation \n",
    "    'nbs': 16                         # Nominal batch size\n",
    "}\n",
    "\n",
    "# Merge base hyperparameters with memory optimizations\n",
    "standard_hyperparams = {**base_hyperparams, **memory_config}\n",
    "hierarchical_hyperparams = {**base_hyperparams, **memory_config}\n",
    "\n",
    "# Special adjustments for hierarchical model (fewer classes, may need different parameters)\n",
    "hierarchical_hyperparams.update({\n",
    "    'cls': 2.0,                       # Reduced class weight (fewer classes)\n",
    "    'epochs': 50,                     # Fewer epochs may be sufficient for taxonomic groups\n",
    "    'patience': 15                    # Earlier stopping \n",
    "})\n",
    "\n",
    "# Display final training configurations\n",
    "print(\"\\nStandard Model Training Configuration:\")\n",
    "for key, value in standard_hyperparams.items():\n",
    "    if key in ['epochs', 'patience', 'optimizer', 'lr0', 'batch', 'image_size', 'device', 'workers', 'amp']:\n",
    "        print(f\"- {key}: {value}\")\n",
    "\n",
    "print(\"\\nHierarchical Model Training Configuration:\")\n",
    "for key, value in hierarchical_hyperparams.items():\n",
    "    if key in ['epochs', 'patience', 'optimizer', 'lr0', 'batch', 'image_size', 'device', 'workers', 'amp']:\n",
    "        print(f\"- {key}: {value}\")\n",
    "\n",
    "# Update training config with hyperparameters\n",
    "training_config[\"hyperparameters\"] = {\n",
    "    \"standard\": standard_hyperparams,\n",
    "    \"hierarchical\": hierarchical_hyperparams,\n",
    "    \"memory_profile\": memory_profile\n",
    "}\n",
    "\n",
    "# Update training config file\n",
    "with open(training_config_path, 'w') as f:\n",
    "    json.dump(training_config, f, indent=2)\n",
    "\n",
    "print(f\"\\nHyperparameters added to training configuration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa6a0fc-d555-4ad0-ba95-81198ce088c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting standard model training on all 30 classes\n",
      "Using base model: yolov8s.pt\n",
      "Dataset path: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038\n",
      "Model will be saved to: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/models/trained/wildlife_detector_20250510_0114\n",
      "\n",
      "Starting training with the following settings:\n",
      "- Model: yolov8s.pt\n",
      "- Epochs: 100\n",
      "- Batch size: 4\n",
      "- Image size: 416px\n",
      "- Device: GPU\n",
      "- Workers: 2\n",
      "\n",
      "Training attempt 1/4\n",
      "New https://pypi.org/project/ultralytics/8.3.130 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.106 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 5898MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038/data.yaml, epochs=100, time=None, patience=25, batch=4, imgsz=416, save=True, save_period=10, cache=ram, device=0, workers=2, project=/home/peter/Desktop/TU PHD/WildlifeDetectionSystem/models/trained, name=wildlife_detector_20250510_01142, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=5, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=3.0, dfl=1.5, pose=12.0, kobj=1.0, nbs=16, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=10.0, translate=0.2, scale=0.6, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.1, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/peter/Desktop/TU PHD/WildlifeDetectionSystem/models/trained/wildlife_detector_20250510_01142\n",
      "Overriding model.yaml nc=80 with nc=30\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2127658  ultralytics.nn.modules.head.Detect           [30, [128, 256, 512]]         \n",
      "Model summary: 129 layers, 11,147,210 parameters, 11,147,194 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038/labels/train.cache... 356 images, 0 backgrounds, 6 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 356/356 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038/images/train/0092_11_09_100BMCIM_IMAG0004.JPG: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0016239]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038/images/train/0870_x_IMAG0009.JPG: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0185256]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038/images/train/1099_21_05_IMAG0136.JPG: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0162761]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038/images/train/1102_21_05_IMAG0134.JPG: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0192918]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038/images/train/1694_21_10_IMAG0251.JPG: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0092396]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038/images/train/1878_21_10_IMAG0203.JPG: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0273335]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 350/350 [00:13<00:00, 26.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038/labels/val.cache... 89 images, 0 backgrounds, 3 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038/images/val/0106_11_09_100BMCIM_IMAG0107.JPG: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.01125]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038/images/val/0748_30_4_24_100BMCIM_IMAG0116.JPG: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0214955]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_export_test_01_20250510_0038/images/val/1345_15_03_24_ÐœÐ¾Ð»Ð»Ð¾Ð²Ð°_ÐºÑƒÑ€Ð¸Ñ_IMAG0389.JPG: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0072291]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:03<00:00, 23.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/models/trained/wildlife_detector_20250510_01142/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/home/peter/Desktop/TU PHD/WildlifeDetectionSystem/models/trained/wildlife_detector_20250510_01142\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100     0.619G      1.978      22.17      1.776          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:11<00:00,  7.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88       0.18      0.151     0.0825      0.037\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100     0.705G      1.896      15.45      1.712          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:10<00:00,  8.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.564     0.0885     0.0757     0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100     0.744G      1.886      14.58      1.724          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:10<00:00,  8.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.702      0.107      0.185      0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100     0.762G       1.93      13.94      1.787          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:13<00:00,  6.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.707      0.145      0.167     0.0829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      0.82G      1.899      13.49      1.737          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:09<00:00,  8.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.528      0.176      0.174     0.0635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      0.82G      1.839      13.06      1.723          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:08<00:00,  9.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.563      0.305      0.211     0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      0.82G      1.848      12.15      1.706          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:08<00:00, 10.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.321      0.215      0.237      0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      0.82G      1.774       11.5      1.683          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:09<00:00,  9.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.545      0.249      0.214     0.0976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      0.82G      1.781      11.87      1.661          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:10<00:00,  8.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.746      0.274      0.393      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      0.82G      1.741      11.51      1.639          1        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:10<00:00,  8.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.527      0.337      0.312      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      0.82G      1.701      10.78      1.638          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:11<00:00,  7.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.634      0.303      0.383      0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      0.82G      1.668      9.882      1.594          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:10<00:00,  8.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.685      0.228      0.269      0.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      0.82G      1.645      9.771      1.589          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:09<00:00,  9.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.632      0.365      0.312      0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      0.82G      1.635      9.793       1.58          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:06<00:00, 13.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.652      0.388      0.345      0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      0.82G      1.702      10.17      1.668          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 15.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.664      0.254      0.288      0.143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      0.82G      1.596      9.741       1.57          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 14.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88       0.68      0.246      0.316      0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      0.82G      1.635      9.388      1.609          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 14.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.731      0.349       0.36      0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      0.82G      1.571      9.395      1.551          1        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:06<00:00, 14.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88       0.52      0.399      0.324      0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      0.82G      1.521      8.964      1.495          6        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 14.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.526      0.396      0.339      0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      0.82G      1.498      8.931      1.498          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:06<00:00, 14.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.654      0.339      0.344      0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      0.82G      1.561      8.935      1.539          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:06<00:00, 14.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.536      0.385      0.354      0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      0.82G      1.435      8.336      1.444          1        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:06<00:00, 14.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 29.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.675      0.387      0.372      0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      0.82G       1.51      8.759      1.511          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:06<00:00, 13.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.705      0.402      0.417      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      0.82G      1.414      8.208      1.456          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:06<00:00, 13.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 26.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.753      0.419      0.447      0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      0.82G      1.439      8.059      1.458          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:06<00:00, 13.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 22.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.665      0.402      0.451      0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      0.82G      1.454      8.133      1.489          6        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:06<00:00, 13.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.538      0.429      0.392       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      0.82G      1.423      7.687      1.442          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:06<00:00, 12.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 19.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.586      0.487      0.423      0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      0.82G      1.449      8.237      1.485          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:06<00:00, 13.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.692      0.388      0.389      0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      0.82G      1.461      7.768      1.467          6        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:03<00:00, 23.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 37.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.759      0.358      0.595      0.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      0.82G       1.45      7.799      1.452          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 20.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 40.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.652      0.452      0.466       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      0.82G      1.362      7.444       1.42          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:03<00:00, 22.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 25.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88       0.61      0.396      0.372       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      0.82G      1.337      7.201      1.377          6        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 15.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.508      0.523      0.392      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      0.82G       1.38      7.484      1.422          1        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 17.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 15.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88       0.65      0.424      0.393      0.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      0.82G      1.324      7.299      1.395          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 16.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.695      0.405      0.383      0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      0.82G      1.371      7.326      1.424          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 17.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.516      0.498      0.392      0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      0.82G      1.351      7.331      1.406          7        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 16.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88       0.55      0.411      0.364      0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      0.82G      1.342       7.23      1.389          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 17.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.671      0.339      0.411      0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      0.82G      1.317      6.622      1.363          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 16.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.589      0.502      0.411      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      0.82G      1.294      6.617       1.36          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 17.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.582      0.506      0.394      0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      0.82G      1.373       7.21       1.39          1        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 16.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 19.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.634      0.473      0.449      0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      0.82G      1.315      7.054      1.388          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 16.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.595      0.518      0.477      0.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      0.82G      1.293      6.853      1.381          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 17.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 32.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.507      0.477      0.425       0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      0.82G      1.295      6.526       1.36          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 17.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.618      0.496      0.463      0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      0.82G       1.29      6.341      1.342          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 17.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 32.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.561      0.504      0.436       0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      0.82G      1.275      6.678      1.361          9        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 16.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.785      0.339      0.408      0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      0.82G        1.3      6.649      1.366          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 17.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 16.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.657      0.391      0.402      0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      0.82G      1.223      6.286      1.331          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 16.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88       0.49      0.473      0.392       0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      0.82G      1.261      6.443      1.342          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 17.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 18.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.505      0.463      0.394      0.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      0.82G      1.187      5.872      1.302          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 16.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.768      0.351      0.392      0.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      0.82G      1.278      6.414      1.364          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 17.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.751      0.392      0.447      0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      0.82G      1.257      6.285      1.365          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 16.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.625      0.461      0.506      0.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      0.82G      1.197      5.999      1.305          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 17.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 16.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.539      0.599      0.414      0.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      0.82G      1.208      6.111      1.313          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 16.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 19.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.475      0.502      0.391       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      0.82G      1.231      6.128      1.331          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:05<00:00, 17.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 17.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.758      0.385      0.422      0.239\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 25 epochs. Best results observed at epoch 29, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=25) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "54 epochs completed in 0.120 hours.\n",
      "Optimizer stripped from /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/models/trained/wildlife_detector_20250510_01142/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/models/trained/wildlife_detector_20250510_01142/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/models/trained/wildlife_detector_20250510_01142/weights/best.pt...\n",
      "Ultralytics 8.3.106 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 5898MiB)\n",
      "Model summary (fused): 72 layers, 11,137,194 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         86         88      0.751      0.358      0.595      0.337\n",
      "         Male Roe Deer         23         23      0.738      0.435      0.796      0.412\n",
      "       Female Roe Deer         14         14      0.446       0.46      0.366      0.227\n",
      "                   Fox          8          8      0.451        0.5      0.426      0.255\n",
      "                Jackal          4          4          1          0      0.364      0.193\n",
      "                Weasel          1          1          1          0      0.249      0.174\n",
      "               Wildcat          1          1          1          0      0.995      0.597\n",
      "                Rabbit         26         27      0.696      0.667      0.732      0.324\n",
      "                 Human          9         10      0.673        0.8      0.836      0.512\n",
      "Speed: 0.1ms preprocess, 15.4ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/peter/Desktop/TU PHD/WildlifeDetectionSystem/models/trained/wildlife_detector_20250510_01142\u001b[0m\n",
      "\n",
      "Training completed in 0h 7m 46s\n",
      "Error during standard model training: 'DetMetrics' object has no attribute 'best_epoch'. See valid attributes below.\n",
      "\n",
      "    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP).\n",
      "\n",
      "    Attributes:\n",
      "        save_dir (Path): A path to the directory where the output plots will be saved.\n",
      "        plot (bool): A flag that indicates whether to plot precision-recall curves for each class.\n",
      "        names (dict): A dictionary of class names.\n",
      "        box (Metric): An instance of the Metric class for storing detection results.\n",
      "        speed (dict): A dictionary for storing execution times of different parts of the detection process.\n",
      "        task (str): The task type, set to 'detect'.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10671/3399800566.py\", line 94, in <module>\n",
      "    \"best_epoch\": standard_results.best_epoch,\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/peter/Desktop/TU PHD/WildlifeDetectionSystem/api/venv/lib/python3.12/site-packages/ultralytics/utils/__init__.py\", line 240, in __getattr__\n",
      "    raise AttributeError(f\"'{name}' object has no attribute '{attr}'. See valid attributes below.\\n{self.__doc__}\")\n",
      "AttributeError: 'DetMetrics' object has no attribute 'best_epoch'. See valid attributes below.\n",
      "\n",
      "    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP).\n",
      "\n",
      "    Attributes:\n",
      "        save_dir (Path): A path to the directory where the output plots will be saved.\n",
      "        plot (bool): A flag that indicates whether to plot precision-recall curves for each class.\n",
      "        names (dict): A dictionary of class names.\n",
      "        box (Metric): An instance of the Metric class for storing detection results.\n",
      "        speed (dict): A dictionary for storing execution times of different parts of the detection process.\n",
      "        task (str): The task type, set to 'detect'.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Standard Model Training\n",
    "# Train the standard model with all species classes\n",
    "\n",
    "from ultralytics import YOLO \n",
    "import time\n",
    "\n",
    "# Function to handle out-of-memory errors during training\n",
    "def train_with_fallback(model, hyperparams, fallbacks=3):\n",
    "    \"\"\"Train with automatic fallback to lower resource config if OOM errors occur\"\"\"\n",
    "    for attempt in range(fallbacks + 1):\n",
    "        try:\n",
    "            print(f\"\\nTraining attempt {attempt + 1}/{fallbacks + 1}\")\n",
    "            # Start training timer\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Train the model with current hyperparams\n",
    "            results = model.train(**hyperparams)\n",
    "            \n",
    "            # If we get here, training was successful\n",
    "            training_time = time.time() - start_time\n",
    "            hours, remainder = divmod(training_time, 3600)\n",
    "            minutes, seconds = divmod(remainder, 60)\n",
    "            \n",
    "            print(f\"\\nTraining completed in {int(hours)}h {int(minutes)}m {int(seconds)}s\")\n",
    "            return results, hyperparams\n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            if 'out of memory' in str(e).lower() and attempt < fallbacks:\n",
    "                print(\"\\nâš ï¸ GPU OUT OF MEMORY ERROR DETECTED âš ï¸\")\n",
    "                print(\"Reducing resource usage and trying again...\")\n",
    "                \n",
    "                # Reduce resource usage\n",
    "                if hyperparams['batch'] > 1:\n",
    "                    hyperparams['batch'] = hyperparams['batch'] // 2\n",
    "                    print(f\"Reduced batch size to {hyperparams['batch']}\")\n",
    "                \n",
    "                if hyperparams['imgsz'] > 320:\n",
    "                    hyperparams['imgsz'] = max(320, hyperparams['imgsz'] - 64)\n",
    "                    print(f\"Reduced image size to {hyperparams['imgsz']}\")\n",
    "                \n",
    "                if hyperparams['device'] != 'cpu' and attempt == fallbacks - 1:\n",
    "                    print(\"Switching to CPU as last resort\")\n",
    "                    hyperparams['device'] = 'cpu'\n",
    "                    hyperparams['workers'] = 0\n",
    "                    hyperparams['amp'] = False\n",
    "                \n",
    "                # Free up GPU memory\n",
    "                torch.cuda.empty_cache()\n",
    "                import gc\n",
    "                gc.collect()\n",
    "                \n",
    "            else:\n",
    "                print(f\"\\nTraining error: {e}\")\n",
    "                return None, hyperparams\n",
    "    \n",
    "    return None, hyperparams\n",
    "\n",
    "# Create model output directories\n",
    "os.makedirs(os.path.join(model_save_dir), exist_ok=True)\n",
    "os.makedirs(standard_model_path, exist_ok=True)\n",
    "\n",
    "print(f\"Starting standard model training on all {len(class_names)} classes\")\n",
    "print(f\"Using base model: {base_model_path}\")\n",
    "print(f\"Dataset path: {standard_export_path}\")\n",
    "print(f\"Model will be saved to: {standard_model_path}\")\n",
    "\n",
    "try:\n",
    "    # Initialize YOLOv8 model\n",
    "    model = YOLO(base_model_path)\n",
    "    \n",
    "    # Set training parameters\n",
    "    standard_params = {\n",
    "        **standard_hyperparams,\n",
    "        'data': os.path.join(standard_export_path, 'data.yaml'),\n",
    "        'project': model_save_dir,\n",
    "        'name': os.path.basename(standard_model_path)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nStarting training with the following settings:\")\n",
    "    print(f\"- Model: {base_model_path}\")\n",
    "    print(f\"- Epochs: {standard_params['epochs']}\")\n",
    "    print(f\"- Batch size: {standard_params['batch']}\")\n",
    "    print(f\"- Image size: {standard_params['imgsz']}px\")\n",
    "    print(f\"- Device: {'CPU' if standard_params['device'] == 'cpu' else 'GPU'}\")\n",
    "    print(f\"- Workers: {standard_params['workers']}\")\n",
    "    \n",
    "    # Train with automatic fallback on OOM errors\n",
    "    standard_results, final_params = train_with_fallback(model, standard_params)\n",
    "    \n",
    "    if standard_results:\n",
    "        # Save final hyperparameters actually used\n",
    "        training_config[\"standard_model\"] = {\n",
    "            \"train_results\": {\n",
    "                \"best_epoch\": standard_results.best_epoch,\n",
    "                \"maps\": standard_results.maps,\n",
    "                \"fitness\": standard_results.fitness\n",
    "            },\n",
    "            \"final_hyperparams\": final_params\n",
    "        }\n",
    "        \n",
    "        # Update training config with results\n",
    "        with open(training_config_path, 'w') as f:\n",
    "            json.dump(training_config, f, indent=2)\n",
    "        \n",
    "        print(\"\\nStandard model training results:\")\n",
    "        print(f\"- Best mAP50-95: {standard_results.maps[0]:.4f}\")\n",
    "        print(f\"- Best mAP50: {standard_results.maps[1]:.4f}\")\n",
    "        print(f\"- Best epoch: {standard_results.best_epoch}\")\n",
    "        print(f\"- Model saved to: {standard_model_path}\")\n",
    "        \n",
    "        # Create a training summary report\n",
    "        summary_path = os.path.join(reports_dir, f\"standard_model_summary_{timestamp_now}.md\")\n",
    "        os.makedirs(os.path.dirname(summary_path), exist_ok=True)\n",
    "        \n",
    "        with open(summary_path, 'w') as f:\n",
    "            f.write(f\"# Standard Wildlife Detection Model Training Summary\\n\\n\")\n",
    "            f.write(f\"## Training Metadata\\n\")\n",
    "            f.write(f\"- **Date and Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"- **Model**: {base_model_path}\\n\")\n",
    "            f.write(f\"- **Dataset**: {standard_export_path}\\n\")\n",
    "            f.write(f\"- **Classes**: {len(class_names)}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"## Training Configuration\\n\")\n",
    "            for param in ['epochs', 'batch', 'image_size', 'device', 'optimizer', 'lr0']:\n",
    "                f.write(f\"- **{param}**: {final_params.get(param, 'N/A')}\\n\")\n",
    "            \n",
    "            f.write(f\"\\n## Performance Metrics\\n\")\n",
    "            f.write(f\"- **Best mAP50-95**: {standard_results.maps[0]:.4f}\\n\")\n",
    "            f.write(f\"- **Best mAP50**: {standard_results.maps[1]:.4f}\\n\")\n",
    "            f.write(f\"- **Best epoch**: {standard_results.best_epoch}\\n\")\n",
    "\n",
    "        print(f\"Training summary saved to: {summary_path}\")\n",
    "        \n",
    "        # Save model path for future notebooks\n",
    "        standard_best_model_path = os.path.join(standard_model_path, \"weights\", \"best.pt\")\n",
    "        training_config[\"standard_best_model_path\"] = standard_best_model_path\n",
    "        \n",
    "        # Update training config with paths to result files\n",
    "        with open(training_config_path, 'w') as f:\n",
    "            json.dump(training_config, f, indent=2)\n",
    "    else:\n",
    "        print(\"\\nStandard model training failed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during standard model training: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7c2da8-d3b2-458a-a3ec-e3b069657658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting hierarchical model training on 5 taxonomic groups\n",
      "Using base model: yolov8s.pt\n",
      "Dataset path: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/data/export/yolo_hierarchical_test_01_20250510_0038\n",
      "Model will be saved to: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/models/trained/wildlife_detector_hierarchical_20250510_0114\n",
      "\n",
      "Starting hierarchical training with the following settings:\n",
      "- Model: yolov8s.pt\n",
      "- Epochs: 50\n",
      "- Batch size: 4\n",
      "Error during hierarchical model training: 'image_size'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_10671/2745908388.py\", line 28, in <module>\n",
      "    print(f\"- Image size: {hierarchical_params['image_size']}\")\n",
      "                           ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
      "KeyError: 'image_size'\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Hierarchical Model Training\n",
    "# Train the hierarchical model with taxonomic groups as classes\n",
    "\n",
    "# Create model output directories\n",
    "os.makedirs(hierarchical_model_path, exist_ok=True)\n",
    "\n",
    "print(f\"\\nStarting hierarchical model training on {len(taxonomic_groups)} taxonomic groups\")\n",
    "print(f\"Using base model: {base_model_path}\")\n",
    "print(f\"Dataset path: {hierarchical_export_path}\")\n",
    "print(f\"Model will be saved to: {hierarchical_model_path}\")\n",
    "\n",
    "try:\n",
    "    # Initialize YOLOv8 model\n",
    "    hierarchical_model = YOLO(base_model_path)\n",
    "    \n",
    "    # Set training parameters\n",
    "    hierarchical_params = {\n",
    "        **hierarchical_hyperparams,\n",
    "        'data': os.path.join(hierarchical_export_path, 'data.yaml'),\n",
    "        'project': model_save_dir,\n",
    "        'name': os.path.basename(hierarchical_model_path)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nStarting hierarchical training with the following settings:\")\n",
    "    print(f\"- Model: {base_model_path}\")\n",
    "    print(f\"- Epochs: {hierarchical_params['epochs']}\")\n",
    "    print(f\"- Batch size: {hierarchical_params['batch']}\")\n",
    "    print(f\"- Image size: {hierarchical_params['image_size']}\")\n",
    "    print(f\"- Device: {'CPU' if hierarchical_params['device'] == 'cpu' else 'GPU'}\")\n",
    "    print(f\"- Workers: {hierarchical_params['workers']}\")\n",
    "    \n",
    "    # Train with automatic fallback on OOM errors\n",
    "    hierarchical_results, final_hierarchical_params = train_with_fallback(hierarchical_model, hierarchical_params)\n",
    "    \n",
    "    if hierarchical_results:\n",
    "        # Save final hyperparameters actually used\n",
    "        training_config[\"hierarchical_model\"] = {\n",
    "            \"train_results\": {\n",
    "                \"best_epoch\": hierarchical_results.best_epoch,\n",
    "                \"maps\": hierarchical_results.maps,\n",
    "                \"fitness\": hierarchical_results.fitness\n",
    "            },\n",
    "            \"final_hyperparams\": final_hierarchical_params\n",
    "        }\n",
    "        \n",
    "        # Update training config with results\n",
    "        with open(training_config_path, 'w') as f:\n",
    "            json.dump(training_config, f, indent=2)\n",
    "        \n",
    "        print(\"\\nHierarchical model training results:\")\n",
    "        print(f\"- Best mAP50-95: {hierarchical_results.maps[0]:.4f}\")\n",
    "        print(f\"- Best mAP50: {hierarchical_results.maps[1]:.4f}\")\n",
    "        print(f\"- Best epoch: {hierarchical_results.best_epoch}\")\n",
    "        print(f\"- Model saved to: {hierarchical_model_path}\")\n",
    "        \n",
    "        # Create a training summary report\n",
    "        hierarchical_summary_path = os.path.join(reports_dir, f\"hierarchical_model_summary_{timestamp_now}.md\")\n",
    "        os.makedirs(os.path.dirname(hierarchical_summary_path), exist_ok=True)\n",
    "        \n",
    "        with open(hierarchical_summary_path, 'w') as f:\n",
    "            f.write(f\"# Hierarchical Wildlife Detection Model Training Summary\\n\\n\")\n",
    "            f.write(f\"## Training Metadata\\n\")\n",
    "            f.write(f\"- **Date and Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"- **Model**: {base_model_path}\\n\")\n",
    "            f.write(f\"- **Dataset**: {hierarchical_export_path}\\n\")\n",
    "            f.write(f\"- **Taxonomic Groups**: {len(taxonomic_groups)}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"## Training Configuration\\n\")\n",
    "            for param in ['epochs', 'batch', 'image_size', 'device', 'optimizer', 'lr0']:\n",
    "                f.write(f\"- **{param}**: {final_hierarchical_params.get(param, 'N/A')}\\n\")\n",
    "            \n",
    "            f.write(f\"\\n## Performance Metrics\\n\")\n",
    "            f.write(f\"- **Best mAP50-95**: {hierarchical_results.maps[0]:.4f}\\n\")\n",
    "            f.write(f\"- **Best mAP50**: {hierarchical_results.maps[1]:.4f}\\n\")\n",
    "            f.write(f\"- **Best epoch**: {hierarchical_results.best_epoch}\\n\")\n",
    "            \n",
    "            f.write(f\"\\n## Taxonomic Groups\\n\")\n",
    "            for group, class_ids in taxonomic_groups.items():\n",
    "                species = [class_names[idx] for idx in class_ids if idx < len(class_names)]\n",
    "                f.write(f\"- **{group}**: {', '.join(species[:5])}\")\n",
    "                if len(species) > 5:\n",
    "                    f.write(f\" and {len(species)-5} more\")\n",
    "                f.write(f\" ({len(species)} species)\\n\")\n",
    "\n",
    "        print(f\"Hierarchical training summary saved to: {hierarchical_summary_path}\")\n",
    "        \n",
    "        # Save model path for future notebooks\n",
    "        hierarchical_best_model_path = os.path.join(hierarchical_model_path, \"weights\", \"best.pt\")\n",
    "        training_config[\"hierarchical_best_model_path\"] = hierarchical_best_model_path\n",
    "        \n",
    "        # Update training config with paths to result files\n",
    "        with open(training_config_path, 'w') as f:\n",
    "            json.dump(training_config, f, indent=2)\n",
    "    else:\n",
    "        print(\"\\nHierarchical model training failed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during hierarchical model training: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6450711-5f52-4140-8d1a-98b0c1b179b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training results...\n",
      "Standard model results not found\n",
      "Hierarchical model results not found\n",
      "Cannot generate visualizations: No results data available\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Training Visualization\n",
    "# Visualize and compare training results\n",
    "\n",
    "def load_results_csv(model_path):\n",
    "    \"\"\"Load and parse the results.csv file from model training\"\"\"\n",
    "    results_path = os.path.join(model_path, 'results.csv')\n",
    "    if os.path.exists(results_path):\n",
    "        try:\n",
    "            return pd.read_csv(results_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading results from {results_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "def plot_training_metrics(standard_df, hierarchical_df=None, metrics=None):\n",
    "    \"\"\"Plot training metrics from results dataframes\"\"\"\n",
    "    if metrics is None:\n",
    "        # Default metrics to plot (handle different column names in YOLOv8)\n",
    "        metrics = []\n",
    "        if standard_df is not None:\n",
    "            cols = standard_df.columns\n",
    "            for metric, patterns in {\n",
    "                'loss': ['train/box_loss', 'box_loss', 'loss'],\n",
    "                'precision': ['metrics/precision(B)', 'precision', 'val/precision'],\n",
    "                'recall': ['metrics/recall(B)', 'recall', 'val/recall'],\n",
    "                'mAP50': ['metrics/mAP50(B)', 'mAP50', 'val/mAP50'],\n",
    "                'mAP50-95': ['metrics/mAP50-95(B)', 'mAP50-95', 'val/mAP50-95'] \n",
    "            }.items():\n",
    "                # Find the first matching column pattern\n",
    "                matching_cols = [col for col in cols if any(pattern in col for pattern in patterns)]\n",
    "                if matching_cols:\n",
    "                    metrics.append((metric, matching_cols[0]))\n",
    "    \n",
    "    # Create subplots for each metric\n",
    "    if not metrics:\n",
    "        print(\"No metrics found in results files\")\n",
    "        return\n",
    "    \n",
    "    n_metrics = len(metrics)\n",
    "    fig, axs = plt.subplots(n_metrics, 1, figsize=(12, 4 * n_metrics))\n",
    "    if n_metrics == 1:\n",
    "        axs = [axs]\n",
    "    \n",
    "    # Plot each metric\n",
    "    for i, (metric_name, col_name) in enumerate(metrics):\n",
    "        ax = axs[i]\n",
    "        \n",
    "        # Plot standard model\n",
    "        if standard_df is not None and col_name in standard_df.columns:\n",
    "            ax.plot(standard_df['epoch'], standard_df[col_name], 'b-', label='Standard')\n",
    "            # Mark best epoch\n",
    "            if 'best_epoch' in training_config.get('standard_model', {}).get('train_results', {}):\n",
    "                best_epoch = training_config['standard_model']['train_results']['best_epoch']\n",
    "                if best_epoch < len(standard_df):\n",
    "                    best_value = standard_df.iloc[best_epoch][col_name]\n",
    "                    ax.plot(best_epoch, best_value, 'bo', markersize=8)\n",
    "                    ax.axvline(x=best_epoch, color='b', linestyle='--', alpha=0.3)\n",
    "        \n",
    "        # Plot hierarchical model if available\n",
    "        if hierarchical_df is not None and col_name in hierarchical_df.columns:\n",
    "            ax.plot(hierarchical_df['epoch'], hierarchical_df[col_name], 'r-', label='Hierarchical')\n",
    "            # Mark best epoch\n",
    "            if 'best_epoch' in training_config.get('hierarchical_model', {}).get('train_results', {}):\n",
    "                best_epoch = training_config['hierarchical_model']['train_results']['best_epoch']\n",
    "                if best_epoch < len(hierarchical_df):\n",
    "                    best_value = hierarchical_df.iloc[best_epoch][col_name]\n",
    "                    ax.plot(best_epoch, best_value, 'ro', markersize=8)\n",
    "                    ax.axvline(x=best_epoch, color='r', linestyle='--', alpha=0.3)\n",
    "        \n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel(metric_name)\n",
    "        ax.set_title(f'{metric_name.upper()} vs. Epoch')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if standard_df is not None and hierarchical_df is not None:\n",
    "            ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plots_dir = os.path.join(reports_dir, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    plot_path = os.path.join(plots_dir, f\"training_metrics_{timestamp_now}.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    print(f\"Saved training metrics plot to: {plot_path}\")\n",
    "    \n",
    "    # Add plot path to training config\n",
    "    training_config[\"plots\"] = {\"training_metrics\": plot_path}\n",
    "    with open(training_config_path, 'w') as f:\n",
    "        json.dump(training_config, f, indent=2)\n",
    "    \n",
    "    return plot_path\n",
    "\n",
    "# Load results\n",
    "print(\"Loading training results...\")\n",
    "standard_results_df = load_results_csv(standard_model_path)\n",
    "hierarchical_results_df = load_results_csv(hierarchical_model_path)\n",
    "\n",
    "if standard_results_df is not None:\n",
    "    print(f\"Loaded standard model results: {len(standard_results_df)} epochs\")\n",
    "else:\n",
    "    print(\"Standard model results not found\")\n",
    "\n",
    "if hierarchical_results_df is not None:\n",
    "    print(f\"Loaded hierarchical model results: {len(hierarchical_results_df)} epochs\")\n",
    "else:\n",
    "    print(\"Hierarchical model results not found\")\n",
    "\n",
    "# Plot training metrics\n",
    "if standard_results_df is not None or hierarchical_results_df is not None:\n",
    "    print(\"\\nGenerating training metrics visualization...\")\n",
    "    plot_path = plot_training_metrics(standard_results_df, hierarchical_results_df)\n",
    "    print(f\"Training visualization complete: {plot_path}\")\n",
    "else:\n",
    "    print(\"Cannot generate visualizations: No results data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29050738-a741-4e9c-adfa-401350605807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output tracking files created:\n",
      "- JSON tracking: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/tracking/notebook2_outputs_20250510_0114.json\n",
      "- Markdown summary: /home/peter/Desktop/TU PHD/WildlifeDetectionSystem/tracking/notebook2_summary_20250510_0114.md\n",
      "\n",
      "These files document all outputs from this notebook for long-term project organization.\n",
      "\n",
      "Model training complete!\n",
      "The trained models are ready for evaluation.\n",
      "Please proceed to the model evaluation notebook (03_model_evaluation.ipynb).\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Output Tracking for Long-Term Project Management\n",
    "# Create detailed tracking of all generated files and models\n",
    "\n",
    "# Create tracking directory if it doesn't exist\n",
    "tracking_dir = os.path.join(project_root, \"tracking\")\n",
    "os.makedirs(tracking_dir, exist_ok=True)\n",
    "\n",
    "# Collect all generated files and their purposes\n",
    "generated_files = {\n",
    "    \"configuration\": {\n",
    "        \"training_config\": training_config_path\n",
    "    },\n",
    "    \"standard_model\": {\n",
    "        \"base_path\": standard_model_path,\n",
    "        \"best_weights\": os.path.join(standard_model_path, \"weights\", \"best.pt\"),\n",
    "        \"last_weights\": os.path.join(standard_model_path, \"weights\", \"last.pt\"),\n",
    "        \"results_csv\": os.path.join(standard_model_path, \"results.csv\"),\n",
    "        \"summary_report\": os.path.join(reports_dir, f\"standard_model_summary_{timestamp_now}.md\")\n",
    "    },\n",
    "    \"hierarchical_model\": {\n",
    "        \"base_path\": hierarchical_model_path,\n",
    "        \"best_weights\": os.path.join(hierarchical_model_path, \"weights\", \"best.pt\"),\n",
    "        \"last_weights\": os.path.join(hierarchical_model_path, \"weights\", \"last.pt\"),\n",
    "        \"results_csv\": os.path.join(hierarchical_model_path, \"results.csv\"),\n",
    "        \"summary_report\": os.path.join(reports_dir, f\"hierarchical_model_summary_{timestamp_now}.md\")\n",
    "    },\n",
    "    \"visualizations\": {\n",
    "        \"training_metrics\": os.path.join(reports_dir, \"plots\", f\"training_metrics_{timestamp_now}.png\")\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create a comprehensive output tracking file\n",
    "tracking_file = os.path.join(tracking_dir, f\"notebook2_outputs_{timestamp_now}.json\")\n",
    "with open(tracking_file, 'w') as f:\n",
    "    json.dump({\n",
    "        \"notebook\": \"02_model_training\",\n",
    "        \"execution_timestamp\": timestamp_now,\n",
    "        \"description\": \"Model training for wildlife detection\",\n",
    "        \"generated_files\": generated_files,\n",
    "        \"training_config\": training_config,\n",
    "        \"next_steps\": {\n",
    "            \"notebook\": \"03_model_evaluation.ipynb\",\n",
    "            \"required_inputs\": [training_config_path]\n",
    "        }\n",
    "    }, f, indent=2)\n",
    "\n",
    "# Create a simple Markdown summary for human-readable reference\n",
    "summary_file = os.path.join(tracking_dir, f\"notebook2_summary_{timestamp_now}.md\")\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(f\"# Model Training Notebook Outputs\\n\\n\")\n",
    "    f.write(f\"**Execution Date:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"## Configuration\\n\\n\")\n",
    "    f.write(f\"- Training Config: `{training_config_path}`\\n\")\n",
    "    f.write(f\"- Model Size: {training_config['model']['name']} ({training_config['model']['description']})\\n\")\n",
    "    f.write(f\"- Hardware: {training_config['hardware']['device']} | Batch Size: {training_config['hardware']['batch_size']} | Image Size: {training_config['hardware']['image_size']}px\\n\\n\")\n",
    "    \n",
    "    # Standard model results\n",
    "    if 'standard_model' in training_config:\n",
    "        std_results = training_config['standard_model']['train_results'] \n",
    "        f.write(f\"## Standard Model Results\\n\\n\")\n",
    "        f.write(f\"- Path: `{standard_model_path}`\\n\")\n",
    "        f.write(f\"- Best Weights: `weights/best.pt`\\n\")\n",
    "        f.write(f\"- Classes: {len(class_names)}\\n\")\n",
    "        f.write(f\"- Best Epoch: {std_results.get('best_epoch', 'N/A')}\\n\")\n",
    "        f.write(f\"- mAP50: {std_results.get('maps', [0, 0])[1]:.4f}\\n\")\n",
    "        f.write(f\"- mAP50-95: {std_results.get('maps', [0])[0]:.4f}\\n\\n\")\n",
    "    \n",
    "    # Hierarchical model results\n",
    "    if 'hierarchical_model' in training_config:\n",
    "        hier_results = training_config['hierarchical_model']['train_results']\n",
    "        f.write(f\"## Hierarchical Model Results\\n\\n\")\n",
    "        f.write(f\"- Path: `{hierarchical_model_path}`\\n\")\n",
    "        f.write(f\"- Best Weights: `weights/best.pt`\\n\")\n",
    "        f.write(f\"- Taxonomic Groups: {len(taxonomic_groups)}\\n\")\n",
    "        f.write(f\"- Best Epoch: {hier_results.get('best_epoch', 'N/A')}\\n\")\n",
    "        f.write(f\"- mAP50: {hier_results.get('maps', [0, 0])[1]:.4f}\\n\")\n",
    "        f.write(f\"- mAP50-95: {hier_results.get('maps', [0])[0]:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"## Next Steps\\n\\n\")\n",
    "    f.write(f\"Proceed to notebook 3 (Model Evaluation) using the training config: `{os.path.basename(training_config_path)}`\")\n",
    "\n",
    "print(f\"\\nOutput tracking files created:\")\n",
    "print(f\"- JSON tracking: {tracking_file}\")\n",
    "print(f\"- Markdown summary: {summary_file}\")\n",
    "print(f\"\\nThese files document all outputs from this notebook for long-term project organization.\")\n",
    "\n",
    "print(\"\\nModel training complete!\")\n",
    "print(\"The trained models are ready for evaluation.\")\n",
    "print(\"Please proceed to the model evaluation notebook (03_model_evaluation.ipynb).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b451e-c824-49d6-a9ea-41dd3709b913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
